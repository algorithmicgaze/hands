{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Training on Pose Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 4090 (UUID: GPU-59ba7a4d-461d-6c44-7eea-a4200c322183)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as D\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_line(lines, prefix):\n",
    "  for line in lines:\n",
    "    if line.startswith('Frames:'):\n",
    "      return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bvh_file(file_path):\n",
    "    # Read file contents\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_contents = f.read()\n",
    "        \n",
    "    # Split file contents by newline characters\n",
    "    lines = file_contents.split('\\n')\n",
    "\n",
    "    # Find the channel names\n",
    "    channel_names = []\n",
    "    joint_name = None\n",
    "    for line in lines:\n",
    "      line = line.strip()\n",
    "      if line.startswith('JOINT') or line.startswith('ROOT'):\n",
    "        # Joint line looks like this:\n",
    "        # JOINT Spine2\n",
    "        joint_data = line.split(' ')\n",
    "        joint_name = joint_data[1]\n",
    "      if line.startswith('CHANNELS'):\n",
    "        # Channels line looks like this:\n",
    "        # CHANNELS 3 Yrotation Xrotation Zrotation\n",
    "        channel_data = line.split(' ')\n",
    "        for channel in channel_data[2:]:\n",
    "          channel_names.append(f'{joint_name}_{channel}')\n",
    "    \n",
    "    # Find the number of frames and the start of the motion data\n",
    "    num_frames_line = find_line(lines, 'Frames:')\n",
    "    num_frames = int(num_frames_line.split(' ')[1])\n",
    "    motion_data_index = lines.index('MOTION') + 3\n",
    "    header = '\\n'.join(lines[:motion_data_index])\n",
    "    \n",
    "    # Find the number of channels in the file\n",
    "    first_frame_data = lines[motion_data_index].strip().split(' ')\n",
    "    num_channels = len(first_frame_data)\n",
    "    print('Channels:', num_channels)\n",
    "\n",
    "    # Extract the motion data as a string\n",
    "    motion_data_str = ''.join(lines[motion_data_index:motion_data_index+num_frames])\n",
    "    \n",
    "    # Convert the motion data to a numpy array\n",
    "    motion_data = np.fromstring(motion_data_str, sep=' ')\n",
    "    motion_data = motion_data.reshape((num_frames, -1))\n",
    "    \n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    motion_tensor = torch.tensor(motion_data, dtype=torch.float32)\n",
    "    \n",
    "    return motion_tensor, header, channel_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 183\n",
      "torch.Size([19298, 183])\n"
     ]
    }
   ],
   "source": [
    "raw_data, header, channel_names = read_bvh_file('train_data/flute2.bvh')\n",
    "print(raw_data.shape)\n",
    "#print(channel_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BVHDataset(Dataset):\n",
    "    def __init__(self, file_path, input_size, output_size, seq_length, future_delta):\n",
    "        self.file_path = file_path\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.seq_length = seq_length\n",
    "        self.future_delta = future_delta\n",
    "\n",
    "        # Read BVH file\n",
    "        self.motion_tensor, self.header, self.channel_names = read_bvh_file(file_path)\n",
    "\n",
    "        # Compute the total number of sequences in the file\n",
    "        self.total_sequences = len(self.motion_tensor) - self.seq_length - self.future_delta\n",
    "\n",
    "        # Compute input_mean and input_std\n",
    "        self.input_mean = torch.mean(self.motion_tensor, dim=(0,))\n",
    "        self.input_std = torch.std(self.motion_tensor, dim=(0,))\n",
    "        self.input_std = torch.where(self.input_std == 0, torch.tensor(1e-7), self.input_std)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_sequences\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Compute the sequence index for the given index\n",
    "        seq_idx = idx + self.seq_length\n",
    "\n",
    "        # Get the sequence of length seq_length as input x\n",
    "        input_tensor = self.motion_tensor[seq_idx - self.seq_length:seq_idx, :self.input_size]\n",
    "\n",
    "        # Get the frame future_delta frames into the future as output y\n",
    "        output_tensor = self.motion_tensor[seq_idx + self.future_delta, :self.output_size]\n",
    "\n",
    "        # Normalize input and output tensors\n",
    "        input_tensor = (input_tensor - self.input_mean) / self.input_std\n",
    "        output_tensor = (output_tensor - self.input_mean[:self.output_size]) / self.input_std[:self.output_size]\n",
    "\n",
    "        return input_tensor, output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 183\n"
     ]
    }
   ],
   "source": [
    "# Create data loaders\n",
    "\n",
    "num_channels = raw_data.shape[-1]\n",
    "input_size = num_channels\n",
    "output_size = num_channels\n",
    "seq_length = 100\n",
    "future_delta = 200\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "dataset = BVHDataset('train_data/flute2.bvh', input_size, output_size, seq_length, future_delta)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PoseTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, output_dim, sequence_length):\n",
    "        super(PoseTransformer, self).__init__()\n",
    "\n",
    "        self.model_dim = model_dim\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.position_encoding = nn.Parameter(torch.randn(sequence_length, 1, model_dim))\n",
    "\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=model_dim * 4,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_dim)\n",
    "        x = self.embedding(x)\n",
    "        # x shape: (sequence_length, batch_size, model_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x + self.position_encoding\n",
    "        x = self.transformer_encoder(x)\n",
    "        # x shape: (batch_size, sequence_length, model_dim)\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # Use only the last frame for prediction\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 183\n",
    "output_dim = 183\n",
    "model_dim = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "sequence_length = 100\n",
    "\n",
    "# Create the model\n",
    "model = PoseTransformer(input_dim, model_dim, num_heads, num_layers, output_dim, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.765806\n",
      "Epoch 1/50, Validation Loss: 0.775133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Train Loss: 0.775260\n",
      "Epoch 2/50, Validation Loss: 0.773287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Train Loss: 0.772943\n",
      "Epoch 3/50, Validation Loss: 0.771553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Train Loss: 0.772199\n",
      "Epoch 4/50, Validation Loss: 0.771681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Train Loss: 0.771967\n",
      "Epoch 5/50, Validation Loss: 0.770930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Train Loss: 0.771752\n",
      "Epoch 6/50, Validation Loss: 0.771028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Train Loss: 0.771739\n",
      "Epoch 7/50, Validation Loss: 0.770969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Train Loss: 0.771655\n",
      "Epoch 8/50, Validation Loss: 0.770765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Train Loss: 0.771561\n",
      "Epoch 9/50, Validation Loss: 0.770582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Train Loss: 0.771546\n",
      "Epoch 10/50, Validation Loss: 0.770415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Train Loss: 0.771775\n",
      "Epoch 11/50, Validation Loss: 0.770447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Train Loss: 0.771458\n",
      "Epoch 12/50, Validation Loss: 0.770595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Train Loss: 0.771534\n",
      "Epoch 13/50, Validation Loss: 0.770394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Train Loss: 0.771367\n",
      "Epoch 14/50, Validation Loss: 0.770696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Train Loss: 0.771528\n",
      "Epoch 15/50, Validation Loss: 0.770463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Train Loss: 0.771353\n",
      "Epoch 16/50, Validation Loss: 0.770816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Train Loss: 0.771398\n",
      "Epoch 17/50, Validation Loss: 0.770471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Train Loss: 0.771301\n",
      "Epoch 18/50, Validation Loss: 0.770826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:09<00:00, 52.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Train Loss: 0.771382\n",
      "Epoch 19/50, Validation Loss: 0.770512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Train Loss: 0.771239\n",
      "Epoch 20/50, Validation Loss: 0.770423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Train Loss: 0.771299\n",
      "Epoch 21/50, Validation Loss: 0.770426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Train Loss: 0.771380\n",
      "Epoch 22/50, Validation Loss: 0.770493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Train Loss: 0.771241\n",
      "Epoch 23/50, Validation Loss: 0.770660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 0.771133\n",
      "Epoch 24/50, Validation Loss: 0.771266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Train Loss: 0.771144\n",
      "Epoch 25/50, Validation Loss: 0.770687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Train Loss: 0.771245\n",
      "Epoch 26/50, Validation Loss: 0.770379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Train Loss: 0.771190\n",
      "Epoch 27/50, Validation Loss: 0.771007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 53.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Train Loss: 0.771243\n",
      "Epoch 28/50, Validation Loss: 0.770407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Train Loss: 0.771167\n",
      "Epoch 29/50, Validation Loss: 0.770765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 0.771187\n",
      "Epoch 30/50, Validation Loss: 0.770550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Train Loss: 0.771150\n",
      "Epoch 31/50, Validation Loss: 0.770327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Train Loss: 0.771098\n",
      "Epoch 32/50, Validation Loss: 0.770446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Train Loss: 0.771105\n",
      "Epoch 33/50, Validation Loss: 0.770378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Train Loss: 0.771209\n",
      "Epoch 34/50, Validation Loss: 0.770746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Train Loss: 0.771161\n",
      "Epoch 35/50, Validation Loss: 0.770714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 0.771111\n",
      "Epoch 36/50, Validation Loss: 0.770425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Train Loss: 0.771076\n",
      "Epoch 37/50, Validation Loss: 0.770495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Train Loss: 0.771122\n",
      "Epoch 38/50, Validation Loss: 0.770496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Train Loss: 0.771139\n",
      "Epoch 39/50, Validation Loss: 0.770400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Train Loss: 0.771155\n",
      "Epoch 40/50, Validation Loss: 0.770451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 0.771119\n",
      "Epoch 41/50, Validation Loss: 0.770496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Train Loss: 0.771122\n",
      "Epoch 42/50, Validation Loss: 0.770558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Train Loss: 0.771108\n",
      "Epoch 43/50, Validation Loss: 0.770438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Train Loss: 0.771097\n",
      "Epoch 44/50, Validation Loss: 0.770557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Train Loss: 0.771117\n",
      "Epoch 45/50, Validation Loss: 0.770545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Train Loss: 0.771047\n",
      "Epoch 46/50, Validation Loss: 0.770353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 0.771355\n",
      "Epoch 47/50, Validation Loss: 0.770442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 54.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Train Loss: 0.771160\n",
      "Epoch 48/50, Validation Loss: 0.770539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Train Loss: 0.771128\n",
      "Epoch 49/50, Validation Loss: 0.770350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 475/475 [00:08<00:00, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Train Loss: 0.771068\n",
      "Epoch 50/50, Validation Loss: 0.770419\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler (optional)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Training on {device}')\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (input_seq, target_seq) in enumerate(tqdm(train_loader)):\n",
    "        input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_seq = model(input_seq)\n",
    "        loss = criterion(output_seq, target_seq)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.6f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_seq, target_seq) in enumerate(val_loader):\n",
    "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "\n",
    "            output_seq = model(input_seq)\n",
    "            loss = criterion(output_seq, target_seq)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(model, seed_sequence, num_frames_to_generate):\n",
    "    model.eval()\n",
    "    generated_sequence = seed_sequence.clone()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_frames_to_generate):\n",
    "            # Get the last sequence_length frames from the generated_sequence\n",
    "            input_seq = generated_sequence[:, -sequence_length:, :]\n",
    "\n",
    "            # Predict the next frame\n",
    "            next_frame = model(input_seq)\n",
    "\n",
    "            # Reshape the predicted frame to have the same dimensions as input_seq\n",
    "            next_frame = next_frame.view(1, 1, -1)\n",
    "\n",
    "            # Append the predicted frame to the generated_sequence\n",
    "            generated_sequence = torch.cat((generated_sequence, next_frame), dim=1)\n",
    "\n",
    "    return generated_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_sequence = torch.randn(1, sequence_length, input_dim).to(device)  # Random seed sequence\n",
    "\n",
    "# Use the first sequence_length frames from the dataset as the seed sequence\n",
    "seed_sequence = raw_data[:sequence_length]\n",
    "seed_sequence = (seed_sequence - dataset.input_mean) / dataset.input_std \n",
    "seed_sequence = seed_sequence.unsqueeze(0).to(device)  \n",
    "#print(raw_data.shape)\n",
    "num_frames_to_generate = 1000\n",
    "\n",
    "generated_sequence = generate_sequence(model, seed_sequence, num_frames_to_generate)\n",
    "generated_sequence = generated_sequence.squeeze(0)\n",
    "generated_sequence = generated_sequence.cpu() * dataset.input_std + dataset.input_mean\n",
    "generated_sequence = generated_sequence.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 183)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bvh_file(file_name, header, predicted_motion):\n",
    "    # Open the file for writing\n",
    "    with open(file_name, 'w') as f:\n",
    "        # Write the header\n",
    "        f.write(header)\n",
    "        f.write('\\n')\n",
    "        # Write the motion data\n",
    "        for frame in predicted_motion:\n",
    "            frame_str = ' '.join(str(x) for x in frame)\n",
    "            f.write(frame_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_bvh_file('out_06.bvh', dataset.header, generated_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
